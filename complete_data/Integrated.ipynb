{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.transform import resize, pyramid_gaussian\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import svm\n",
    "from skimage.feature import hog\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import os\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GestureRecognizer(object):\n",
    "\n",
    "    \"\"\"class to perform gesture recognition\"\"\"\n",
    "\n",
    "    def __init__(self, data_directory):\n",
    "\n",
    "        \"\"\"\n",
    "            data_directory : path like /home/sanket/mlproj/dataset/\n",
    "            includes the dataset folder with '/'\n",
    "\n",
    "            Initialize all your variables here\n",
    "        \"\"\"\n",
    "        self.base_dir = data_directory\n",
    "        # self.base_dir = os.path.abspath('.') + '/dataset/'\n",
    "        self.win_size = 128\n",
    "        self.clf_gesture = None\n",
    "        self.clf_hnh = None\n",
    "\n",
    "    def IOU(self, A, B):\n",
    "        x_overlap = max(0, min(B[0],B[2]) - max(A[0],A[2]))\n",
    "        y_overlap = max(0, min(B[1],B[3]) - max(A[1],A[3]))\n",
    "        inter = x_overlap * y_overlap;\n",
    "        \n",
    "        A_area = (A[2] - A[0] + 1)*(A[3] - A[1] + 1)\n",
    "        B_area = (B[2] - B[0] + 1)*(B[3] - B[1] + 1)\n",
    "        \n",
    "        union = (A_area + B_area - inter)*1.0\n",
    "        inter = inter*1.0\n",
    "        \n",
    "        return inter/union\n",
    "    \n",
    "    def train(self, train_list):\n",
    "\n",
    "        \"\"\"\n",
    "            train_list : list of users to use for training\n",
    "            eg [\"user_1\", \"user_2\", \"user_3\"]\n",
    "\n",
    "            The train function should train all your classifiers,\n",
    "            both binary and multiclass on the given list of users\n",
    "        \"\"\"\n",
    "        \n",
    "        train_x_pos_ = []\n",
    "        train_x_neg_ = []\n",
    "        train_y = []\n",
    "        \n",
    "        for user in train_list:\n",
    "            csv_file = self.base_dir + user + '/' + user + '_loc.csv'\n",
    "            with open(csv_file,'r') as f:\n",
    "                f.readline()\n",
    "                for line in f:\n",
    "                    data = line.strip().split(',')\n",
    "                    file_name = data[0]\n",
    "                    x1,y1,x2,y2 = map(int, data[1:])\n",
    "                    \n",
    "                    img = io.imread(self.base_dir + file_name,as_grey=True)\n",
    "                    h,w = img.shape[:2]\n",
    "                    imgg = img[y1:y2,x1:x2]\n",
    "                    imgg = resize(imgg, (self.win_size, self.win_size))\n",
    "                    imgg_hog = hog(imgg)\n",
    "                    \n",
    "                    label = ord(file_name.split('/')[1][0])\n",
    "                    \n",
    "                    train_x_pos_.append(imgg_hog)\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "                    count = 0\n",
    "                    \n",
    "                    A = [x1,y1,x2,y2]\n",
    "                    \n",
    "                    while True:\n",
    "                        x1_r = random.randrange(0,w - self.win_size)\n",
    "                        y1_r = random.randrange(0,h - self.win_size)\n",
    "                        x2_r = x1_r + self.win_size\n",
    "                        y2_r = y1_r + self.win_size\n",
    "                        \n",
    "                        if y2_r >= h or x2_r>=w:\n",
    "                            continue\n",
    "                        \n",
    "                        B = [x1_r, y1_r, x2_r, y2_r]\n",
    "                        \n",
    "                        if self.IOU(A,B) < 0.1:\n",
    "                            train_x_neg_.append(hog(img[y1_r:y2_r,x1_r:x2_r]))\n",
    "                            count += 1\n",
    "                        \n",
    "                        if count >= 2:\n",
    "                            break\n",
    "        \n",
    "        self.train_x_pos = np.asarray(train_x_pos_)\n",
    "        del train_x_pos_\n",
    "        self.train_x_neg = np.asarray(train_x_neg_)\n",
    "        del train_x_neg_\n",
    "        train_y = np.asarray(train_y)\n",
    "        \n",
    "        self.clf_gesture =  svm.LinearSVC()\n",
    "        self.clf_gesture.fit(self.train_x_pos, train_y)\n",
    "        score_gesture = self.clf_gesture.score(self.train_x_pos, train_y)\n",
    "        print 'Training accuracy for gesture classifier : %f' %(score_gesture)\n",
    "        \n",
    "#         self.clf_hnh = svm.LinearSVC()\n",
    "        self.clf_hnh = GaussianNB()\n",
    "        train_x_hnh = np.concatenate((self.train_x_pos , self.train_x_neg))\n",
    "        train_y_hnh = np.asarray( [1] * len(self.train_x_pos) + [0] * len(self.train_x_neg))\n",
    "        self.clf_hnh.partial_fit(train_x_hnh, train_y_hnh, classes = np.asarray([0,1]))\n",
    "        score_hnh = self.clf_hnh.score(train_x_hnh, train_y_hnh)\n",
    "        print 'Training accuracy for Hand/Non-hand classifier : %f' %(score_hnh)\n",
    "    \n",
    "    \n",
    "    def test(self, test_list):\n",
    "\n",
    "        \"\"\"\n",
    "            train_list : list of users to use for training\n",
    "            eg [\"user_1\", \"user_2\", \"user_3\"]\n",
    "\n",
    "            The train function should train all your classifiers,\n",
    "            both binary and multiclass on the given list of users\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.clf_hnh is None or self.clf_gesture is None:\n",
    "            print 'Classifiers not trained'\n",
    "            return\n",
    "        \n",
    "        test_x_pos = []\n",
    "        test_x_neg = []\n",
    "        test_y = []\n",
    "        \n",
    "        for user in test_list:\n",
    "            csv_file = self.base_dir + user + '/' + user + '_loc.csv'\n",
    "            with open(csv_file,'r') as f:\n",
    "                f.readline()\n",
    "                for line in f:\n",
    "                    data = line.strip().split(',')\n",
    "                    file_name = data[0]\n",
    "                    x1,y1,x2,y2 = map(int, data[1:])\n",
    "                    \n",
    "                    img = io.imread(self.base_dir + file_name,as_grey=True)\n",
    "                    h,w = img.shape[:2]\n",
    "                    imgg = img[y1:y2,x1:x2]\n",
    "                    imgg = resize(imgg, (self.win_size, self.win_size))\n",
    "                    imgg_hog = hog(imgg)\n",
    "                    \n",
    "                    label = ord(file_name.split('/')[1][0])\n",
    "                    \n",
    "                    test_x_pos.append(imgg_hog)\n",
    "                    test_y.append(label)\n",
    "                    \n",
    "                    count = 0\n",
    "                    \n",
    "                    A = [x1,y1,x2,y2]\n",
    "                    \n",
    "                    while True:\n",
    "                        x1_r = random.randrange(0,w - self.win_size)\n",
    "                        y1_r = random.randrange(0,h - self.win_size)\n",
    "                        x2_r = x1_r + self.win_size\n",
    "                        y2_r = y1_r + self.win_size\n",
    "                        \n",
    "                        if y2_r >= h or x2_r>=w:\n",
    "                            continue\n",
    "                        \n",
    "                        B = [x1_r, y1_r, x2_r, y2_r]\n",
    "                        \n",
    "                        if self.IOU(A,B) < 0.1:\n",
    "                            test_x_neg.append(hog(img[y1_r:y2_r,x1_r:x2_r]))\n",
    "                            count += 1\n",
    "                        \n",
    "                        if count >= 2:\n",
    "                            break\n",
    "        \n",
    "        \n",
    "        test_x_pos = np.asarray(test_x_pos)\n",
    "        test_x_neg = np.asarray(test_x_neg)\n",
    "        test_y = np.asarray(test_y)\n",
    "        \n",
    "        score_gesture = self.clf_gesture.score(test_x_pos, test_y)\n",
    "        print 'Testing accuracy for gesture classifier : %f' %(score_gesture)\n",
    "        \n",
    "        \n",
    "        test_x_hnh = np.concatenate((test_x_pos, test_x_neg))\n",
    "        test_y_hnh = np.asarray( [1] * len(test_x_pos) + [0] * len(test_x_neg) )\n",
    "        \n",
    "        score_hnh = self.clf_hnh.score(test_x_hnh,test_y_hnh)\n",
    "        print 'Testing accuracy for Hand/Non-hand classifier : %f' %(score_hnh)\n",
    "\n",
    "    \n",
    "    def hard_negative_mining(self, no_iter, threshold):\n",
    "        \n",
    "        if self.clf_hnh is None or self.clf_gesture is None:\n",
    "            print 'Classifiers not trained'\n",
    "            return\n",
    "        \n",
    "        for i in xrange(no_iter):\n",
    "            count = 0\n",
    "            FP = []\n",
    "            \n",
    "            for data in self.train_x_neg:\n",
    "                if self.clf_hnh.predict([data])[0] == 1:\n",
    "                    count+=1\n",
    "                    FP.append(data)\n",
    "            \n",
    "            print count\n",
    "            if count <= threshold:\n",
    "                break\n",
    "            \n",
    "            self.clf_hnh.partial_fit(np.asarray(FP), np.asarray([0] * len(FP)))\n",
    "        \n",
    "        Y = np.asarray([1] * self.train_x_pos.shape[0] +  [0] * self.train_x_neg.shape[0])\n",
    "        score_ = self.clf_hnh.score(np.concatenate((self.train_x_pos, self.train_x_neg)), Y)\n",
    "        print 'Accuracy for Hand/Non-hand classifier after Hard Negative Mining : %f' %(score_)\n",
    "        \n",
    "    def sliding_window(self, img):\n",
    "        # conf_map = np.zeros(img.shape)\n",
    "        \n",
    "        h,w = img.shape[:2]\n",
    "        stride = 10\n",
    "        win_size = 128\n",
    "        \n",
    "        max_class = 0\n",
    "        X = 0\n",
    "        Y = 0\n",
    "        \n",
    "        for y in range(0,h-win_size+1,stride):\n",
    "            for x in range(0,w-win_size+1,stride):\n",
    "                imgg = img[y:y+win_size, x:x+win_size]\n",
    "                hog_ = hog(imgg)\n",
    "                class_ = self.clf_hnh.predict_proba(np.asarray([hog_]))[0][1]\n",
    "                if class_ > max_class:\n",
    "                    max_class = class_\n",
    "                    X = x\n",
    "                    Y = y\n",
    "                # for i in range(128):\n",
    "                    # for j in range(128):\n",
    "                        # conf_map[y + i][x + j] = max(conf_map[y + i][x + j], class_)\n",
    "        # return conf_map, X, Y\n",
    "        return max_class, Y, X\n",
    "    \n",
    "    def get_bbox(self, image):\n",
    "        \n",
    "        if self.clf_hnh is None or self.clf_gesture is None:\n",
    "            print 'Classifiers not trained'\n",
    "            return\n",
    "        \n",
    "        downscale_ = 1.3\n",
    "        py = pyramid_gaussian(image, downscale = downscale_)\n",
    "        py_img  = [py.next(), py.next(), py.next()]\n",
    "        \n",
    "        index = 0\n",
    "        pos = [0,0,128,128]\n",
    "        max_c_val = 0\n",
    "        for i in xrange(len(py_img)):\n",
    "            c_val, x, y = self.sliding_window(py_img[i])\n",
    "            if c_val > max_c_val:\n",
    "                factor = downscale_**i\n",
    "                max_c_val = c_val\n",
    "                pos = [x,y,x+128,y+128]\n",
    "                pos = map(lambda x : int(x*factor), pos)\n",
    "                \n",
    "        return pos\n",
    "        \n",
    "    def recognize_gesture(self, image):\n",
    "\n",
    "        \"\"\"\n",
    "            image : a 320x240 pixel RGB image in the form of a numpy array\n",
    "            \n",
    "            This function should locate the hand and classify the gesture.\n",
    "\n",
    "            returns : (position, label)\n",
    "\n",
    "            position : a tuple of (x1,y1,x2,y2) coordinates of bounding box\n",
    "                       x1,y1 is top left corner, x2,y2 is bottom right\n",
    "\n",
    "            label : a single character. eg 'A' or 'B'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            position = self.get_bbox(image)\n",
    "            imgg = image[position[0]:position[2], position[1] : position[3]]\n",
    "            imgg = resize(imgg, (self.win_size, self.win_size))\n",
    "            label = chr(self.clf_gesture.predict(np.asarray( [hog(imgg)]))[0])\n",
    "            return position, label\n",
    "        except Exception as e:\n",
    "            print e\n",
    "\n",
    "    def translate_video(self, image_array):\n",
    "\n",
    "        \"\"\"\n",
    "            image_array : a list of images as described above.\n",
    "                          can be of arbitrary length\n",
    "\n",
    "            This function classifies the video into a 5 character string\n",
    "\n",
    "            returns : word (a string of 5 characters)\n",
    "                    no two consecutive characters are identical\n",
    "        \"\"\"\n",
    "\n",
    "        return word\n",
    "    \n",
    "    def test_labelled_images(self):\n",
    "        \n",
    "        if self.clf_hnh is None or self.clf_gesture is None:\n",
    "            print 'Classifiers not trained'\n",
    "            return\n",
    "\n",
    "        test_list = [3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19]\n",
    "        test_list = map(lambda x : 'user_' + str(x), test_list)\n",
    "        \n",
    "        count = 0\n",
    "        total = 0\n",
    "        for user in test_list:\n",
    "            \n",
    "            print user\n",
    "            \n",
    "            csv_file = self.base_dir + user + '/' + user + '_loc.csv'\n",
    "            with open(csv_file,'r') as f:\n",
    "                f.readline()\n",
    "                for line in f:\n",
    "                    data = line.strip().split(',')\n",
    "                    file_name = data[0]\n",
    "                    x1,y1,x2,y2 = map(int, data[1:])\n",
    "                    \n",
    "                    img = io.imread(self.base_dir + file_name,as_grey=True)\n",
    "                    total+=1\n",
    "                    h,w = img.shape[:2]\n",
    "                    label = file_name.split('/')[1][0]\n",
    "                    \n",
    "                    pos, label_ = self.recognize_gesture(img)\n",
    "                    \n",
    "                    if label == label_:\n",
    "                        count+=1\n",
    "        \n",
    "        score_gesture = (count*1.0)/(total*1.0)\n",
    "        print 'Testing accuracy for gesture classifier class : %f' %(score_gesture)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ayush/GPU_ML/ML/workspace/project/complete_data/dataset/\n"
     ]
    }
   ],
   "source": [
    "G = GestureRecognizer(os.path.abspath('.') + '/dataset/')\n",
    "print G.base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_3', 'user_4', 'user_5', 'user_6', 'user_7', 'user_9', 'user_10', 'user_11', 'user_12', 'user_13', 'user_14', 'user_15']\n",
      "['user_16', 'user_17', 'user_18', 'user_19']\n"
     ]
    }
   ],
   "source": [
    "user = [3,4,5,6,7,9,10,11,12,13,14,15]\n",
    "user = map(lambda x : 'user_' + str(x), user)\n",
    "print user\n",
    "\n",
    "user_test = [16,17,18,19]\n",
    "user_test = map(lambda x : 'user_' + str(x), user_test)\n",
    "print user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for gesture classifier : 1.000000\n",
      "Training accuracy for Hand/Non-hand classifier : 0.904167\n"
     ]
    }
   ],
   "source": [
    "G.train(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696\n",
      "539\n",
      "460\n",
      "394\n",
      "350\n",
      "316\n",
      "298\n",
      "278\n",
      "264\n",
      "238\n",
      "223\n",
      "210\n",
      "201\n",
      "194\n",
      "180\n",
      "172\n",
      "170\n",
      "154\n",
      "151\n",
      "143\n",
      "133\n",
      "127\n",
      "119\n",
      "121\n",
      "120\n",
      "107\n",
      "102\n",
      "107\n",
      "93\n",
      "91\n",
      "92\n",
      "84\n",
      "87\n",
      "80\n",
      "78\n",
      "66\n",
      "70\n",
      "68\n",
      "56\n",
      "56\n",
      "58\n",
      "55\n",
      "53\n",
      "55\n",
      "56\n",
      "52\n",
      "54\n",
      "50\n",
      "57\n",
      "51\n",
      "Accuracy for Hand/Non-hand classifier after Hard Negative Mining : 0.961343\n"
     ]
    }
   ],
   "source": [
    "G.hard_negative_mining(50,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for gesture classifier : 0.764583\n",
      "Testing accuracy for Hand/Non-hand classifier : 0.922569\n"
     ]
    }
   ],
   "source": [
    "G.test(user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_3\n",
      "user_4\n",
      "user_5\n",
      "user_6\n",
      "user_7\n",
      "user_9\n",
      "user_10\n",
      "user_11\n",
      "user_12\n",
      "user_13\n",
      "user_14\n",
      "user_15\n",
      "user_16\n",
      "user_17\n",
      "user_18\n",
      "user_19\n",
      "Testing accuracy for gesture classifier class : 0.331510\n"
     ]
    }
   ],
   "source": [
    "G.test_labelled_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(G.clf_hnh, 'clf_hnh_good_96_93.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
