{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import svm\n",
    "from skimage.feature import hog\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GestureRecognizer(object):\n",
    "\n",
    "    \"\"\"class to perform gesture recognition\"\"\"\n",
    "\n",
    "    def __init__(self, data_directory):\n",
    "\n",
    "        \"\"\"\n",
    "            data_directory : path like /home/sanket/mlproj/dataset/\n",
    "            includes the dataset folder with '/'\n",
    "\n",
    "            Initialize all your variables here\n",
    "        \"\"\"\n",
    "        self.base_dir = data_directory\n",
    "        # self.base_dir = os.path.abspath('.') + '/dataset/'\n",
    "        self.win_size = 128\n",
    "\n",
    "    def IOU(self, A, B):\n",
    "        x_overlap = max(0, min(B[0],B[2]) - max(A[0],A[2]))\n",
    "        y_overlap = max(0, min(B[1],B[3]) - max(A[1],A[3]))\n",
    "        inter = x_overlap * y_overlap;\n",
    "        \n",
    "        A_area = (A[2] - A[0] + 1)*(A[3] - A[1] + 1)\n",
    "        B_area = (B[2] - B[0] + 1)*(B[3] - B[1] + 1)\n",
    "        \n",
    "        union = (A_area + B_area - inter)*1.0\n",
    "        inter = inter*1.0\n",
    "        \n",
    "        return inter/union\n",
    "    \n",
    "    def train(self, train_list):\n",
    "\n",
    "        \"\"\"\n",
    "            train_list : list of users to use for training\n",
    "            eg [\"user_1\", \"user_2\", \"user_3\"]\n",
    "\n",
    "            The train function should train all your classifiers,\n",
    "            both binary and multiclass on the given list of users\n",
    "        \"\"\"\n",
    "        \n",
    "        train_x_pos = []\n",
    "        train_x_neg = []\n",
    "        train_y = []\n",
    "        \n",
    "        for user in train_list:\n",
    "            csv_file = self.base_dir + user + '/' + user + '_loc.csv'\n",
    "            with open(csv_file,'r') as f:\n",
    "                f.readline()\n",
    "                for line in f:\n",
    "                    data = line.strip().split(',')\n",
    "                    file_name = data[0]\n",
    "                    x1,y1,x2,y2 = map(int, data[1:])\n",
    "                    \n",
    "                    img = io.imread(self.base_dir + file_name,as_grey=True)\n",
    "                    h,w = img.shape[:2]\n",
    "                    imgg = img[y1:y2,x1:x2]\n",
    "                    imgg = resize(imgg, (self.win_size, self.win_size))\n",
    "                    imgg_hog = hog(imgg)\n",
    "                    \n",
    "                    label = ord(file_name.split('/')[1][0])\n",
    "                    \n",
    "                    train_x_pos.append(imgg_hog)\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "                    count = 0\n",
    "                    \n",
    "                    A = [x1,y1,x2,y2]\n",
    "                    \n",
    "                    while True:\n",
    "                        x1_r = random.randrange(0,w - self.win_size)\n",
    "                        y1_r = random.randrange(0,h - self.win_size)\n",
    "                        x2_r = x1_r + self.win_size\n",
    "                        y2_r = y1_r + self.win_size\n",
    "                        \n",
    "                        if y2_r >= h or x2_r>=w:\n",
    "                            continue\n",
    "                        \n",
    "                        B = [x1_r, y1_r, x2_r, y2_r]\n",
    "                        \n",
    "                        if self.IOU(A,B) < 0.1:\n",
    "                            train_x_neg.append(hog(img[y1_r:y2_r,x1_r:x2_r]))\n",
    "                            count += 1\n",
    "                        \n",
    "                        if count >= 2:\n",
    "                            break\n",
    "        \n",
    "        self.clf_gesture =  svm.LinearSVC()\n",
    "        self.clf_gesture.fit(np.asarray(train_x_pos), np.asarray(train_y))\n",
    "        score_gesture = self.clf_gesture.score(np.asarray(train_x_pos), np.asarray(train_y))\n",
    "        print 'Training accuracy for gesture classifier : %f' %(score_gesture)\n",
    "        \n",
    "        self.clf_hnh = svm.LinearSVC()\n",
    "        train_x_hnh = train_x_pos + train_x_neg\n",
    "        train_y_hnh = [1] * len(train_x_pos) + [0] * len(train_x_neg)\n",
    "        self.clf_hnh.fit(np.asarray(train_x_hnh), np.asarray(train_y_hnh))\n",
    "        score_hnh = self.clf_hnh.score(np.asarray(train_x_hnh), np.asarray(train_y_hnh))\n",
    "        print 'Training accuracy for Hand/Non-hand classifier %f' %(score_hnh)\n",
    "    \n",
    "    \n",
    "    def test(self, test_list):\n",
    "\n",
    "        \"\"\"\n",
    "            train_list : list of users to use for training\n",
    "            eg [\"user_1\", \"user_2\", \"user_3\"]\n",
    "\n",
    "            The train function should train all your classifiers,\n",
    "            both binary and multiclass on the given list of users\n",
    "        \"\"\"\n",
    "        \n",
    "        test_x_pos = []\n",
    "        test_x_neg = []\n",
    "        test_y = []\n",
    "        \n",
    "        for user in test_list:\n",
    "            csv_file = self.base_dir + user + '/' + user + '_loc.csv'\n",
    "            with open(csv_file,'r') as f:\n",
    "                f.readline()\n",
    "                for line in f:\n",
    "                    data = line.strip().split(',')\n",
    "                    file_name = data[0]\n",
    "                    x1,y1,x2,y2 = map(int, data[1:])\n",
    "                    \n",
    "                    img = io.imread(self.base_dir + file_name,as_grey=True)\n",
    "                    h,w = img.shape[:2]\n",
    "                    imgg = img[y1:y2,x1:x2]\n",
    "                    imgg = resize(imgg, (self.win_size, self.win_size))\n",
    "                    imgg_hog = hog(imgg)\n",
    "                    \n",
    "                    label = ord(file_name.split('/')[1][0])\n",
    "                    \n",
    "                    test_x_pos.append(imgg_hog)\n",
    "                    test_y.append(label)\n",
    "                    \n",
    "                    count = 0\n",
    "                    \n",
    "                    A = [x1,y1,x2,y2]\n",
    "                    \n",
    "                    while True:\n",
    "                        x1_r = random.randrange(0,w - self.win_size)\n",
    "                        y1_r = random.randrange(0,h - self.win_size)\n",
    "                        x2_r = x1_r + self.win_size\n",
    "                        y2_r = y1_r + self.win_size\n",
    "                        \n",
    "                        if y2_r >= h or x2_r>=w:\n",
    "                            continue\n",
    "                        \n",
    "                        B = [x1_r, y1_r, x2_r, y2_r]\n",
    "                        \n",
    "                        if self.IOU(A,B) < 0.1:\n",
    "                            test_x_neg.append(hog(img[y1_r:y2_r,x1_r:x2_r]))\n",
    "                            count += 1\n",
    "                        \n",
    "                        if count >= 2:\n",
    "                            break\n",
    "        \n",
    "        score_gesture = self.clf_gesture.score(np.asarray(test_x_pos), np.asarray(test_y))\n",
    "        print 'Testing accuracy for gesture classifier : %f' %(score_gesture)\n",
    "        \n",
    "        \n",
    "        test_x_hnh = test_x_pos + test_x_neg\n",
    "        test_y_hnh = [1] * len(test_x_pos) + [0] * len(test_x_neg)\n",
    "        \n",
    "        score_hnh = self.clf_hnh.score(np.asarray(test_x_hnh), np.asarray(test_y_hnh))\n",
    "        print 'Training accuracy for Hand/Non-hand classifier %f' %(score_hnh)\n",
    "\n",
    "    \n",
    "    def recognize_gesture(self, image):\n",
    "\n",
    "        \"\"\"\n",
    "            image : a 320x240 pixel RGB image in the form of a numpy array\n",
    "            \n",
    "            This function should locate the hand and classify the gesture.\n",
    "\n",
    "            returns : (position, label)\n",
    "\n",
    "            position : a tuple of (x1,y1,x2,y2) coordinates of bounding box\n",
    "                       x1,y1 is top left corner, x2,y2 is bottom right\n",
    "\n",
    "            label : a single character. eg 'A' or 'B'\n",
    "        \"\"\"\n",
    "\n",
    "        return position, label\n",
    "\n",
    "    def translate_video(self, image_array):\n",
    "\n",
    "        \"\"\"\n",
    "            image_array : a list of images as described above.\n",
    "                          can be of arbitrary length\n",
    "\n",
    "            This function classifies the video into a 5 character string\n",
    "\n",
    "            returns : word (a string of 5 characters)\n",
    "                    no two consecutive characters are identical\n",
    "        \"\"\"\n",
    "\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ayush/GPU_ML/ML/workspace/project/complete_data/dataset/\n"
     ]
    }
   ],
   "source": [
    "G = GestureRecognizer(os.path.abspath('.') + '/dataset/')\n",
    "print G.base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_3', 'user_4', 'user_5', 'user_6', 'user_7', 'user_9', 'user_10', 'user_11', 'user_12', 'user_13', 'user_14', 'user_15']\n"
     ]
    }
   ],
   "source": [
    "user = [3,4,5,6,7,9,10,11,12,13,14,15]\n",
    "user = map(lambda x : 'user_' + str(x), user)\n",
    "print user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for gesture classifier : 1.000000\n",
      "Training accuracy for Hand/Non-hand classifier 1.000000\n"
     ]
    }
   ],
   "source": [
    "G.train(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_16', 'user_17', 'user_18', 'user_19']\n"
     ]
    }
   ],
   "source": [
    "user_test = [16,17,18,19]\n",
    "user_test = map(lambda x : 'user_' + str(x), user_test)\n",
    "print user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for gesture classifier : 0.764583\n",
      "Training accuracy for Hand/Non-hand classifier 0.968056\n"
     ]
    }
   ],
   "source": [
    "G.test(user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
